# Решение тестового задания 

## Вся последовательность действий и анализ описаны ниже, графики представлены в самом решении, предложения по улучшению решения представлены в самом конце.

### Загрузка и предварительная обработка данных

Для выполнения задачи прогнозирования качества вин был использован набор данных, содержащий различные характеристики вин и их оценки качества. 

### Исследовательский анализ данных (EDA)

Перед тем как приступить к построению модели, был проведен предварительный анализ данных:

 **Распределение качества вин**:
   Для анализа распределения качества использовался график `sns.countplot`, отображающий частоту встречаемости каждого уровня качества (от 3 до 9). График был разделен по типам вин (красные и белые).

 **Процент низкого качества вин**:
   Были рассчитаны проценты низкого качества вин для каждого типа. Для красных вин процент с оценкой качества ниже или равной 4 составил около 3.94%, для белых вин 3.73%.

 **Корреляция признаков с качеством**:
   Для понимания важности признаков, влияющих на качество вина, был построен столбчатый график, показывающий корреляцию каждого признака с переменной качества. Также был использован `sns.clustermap`, отображающий тепловую карту корреляций между признаками.

### Построение первой модели (SVC)

На этом этапе было принято решение протестировать классификатор **SVM (SVC)**, чтобы оценить его способность предсказывать качество вин ну и просто попробовать первый заход так скажем. 

 **Предобработка данных**:
   Столбец `type` был преобразован в бинарную переменную с помощью `pd.get_dummies`. После этого данные были разделены на признаки X и целевую переменную y.

 **Разделение данных на обучающую и тестовую выборки**:
   Для обучения и тестирования модели был использован метод `train_test_split`, где 80% данных было выделено для обучения, а оставшиеся 20% — для тестирования.

 **Масштабирование данных**:
   Для улучшения производительности SVM был применен `StandardScaler`, который нормализует данные, что важно для метода SVM.

 **Построение пайплайна**:
   Были созданы последовательные шаги с использованием `Pipeline`, включающие масштабирование данных и классификатор SVM.

 **Настройка гиперпараметров модели**:
   Для поиска оптимальных гиперпараметров был использован `GridSearchCV`, который проводил кросс-валидацию по различным значениям гиперпараметров (веса классов, C и gamma для SVM).

 **Обучение модели**:
   Модель была обучена на тренировочных данных, и результаты были оценены на тестовой выборке.

### Результаты и метрики

После обучения модели были получены следующие результаты:

- **Коэффициент детерминации (R^2)**: -0.681
- **Средняя абсолютная ошибка (MAE)**: 0.788
- **Отчет по классификации**:
  Модель показала низкие результаты по точности и полноте для классов с высоким качеством (7, 8, 9), особенно для редких классов (класс 9 с 3 экземплярами). Это говорит о несбалансированности данных и возможной проблеме с классификацией редких классов.

- **Точность (Accuracy)**: 0.40, что указывает на необходимость улучшения модели, особенно для предсказания редких классов качества.

---

Вот обновленное описание, с добавленными предложениями по улучшению и объяснением обучения с использованием градиентного спуска и функций активации:

---

### Построение модели с использованием нейронной сети

В качестве следующего подхода была выбрана нейронная сеть с несколькими слоями Feedforward Neural Network.

 **Предобработка данных**:
   Данные были разделены на признаки X и целевую переменную(y. Затем данные были масштабированы с помощью `StandardScaler`. Признаки для обучающей и тестовой выборок были нормализованы, а целевая переменная была преобразована в категориальные метки с использованием функции `to_categorical`. Это необходимо для многоклассовой классификации.

 **Архитектура нейронной сети**:
   Модель состояла из трех слоев:
   - Входной слой с 64 нейронами и функцией активации ReLU.
   - Скрытый слой с 32 нейронами и функцией активации ReLU.
   - Выходной слой с количеством нейронов, соответствующим числу классов качества вина, и функцией активации Softmax для многоклассовой классификации.

 **Компиляция и обучение модели**:
   Для обучения модели использовался **оптимизатор Adam** с коэффициентом обучения 0.001. Функция потерь **categorical_crossentropy** была выбрана для многоклассовой задачи, так как она оптимальна для классификации.

 **Оценка результатов**:
   После обучения модель была протестирована на тестовой выборке, и предсказания были преобразованы обратно в исходные классы с помощью функции `np.argmax`. Для оценки производительности были использованы следующие метрики:
   - **Коэффициент детерминации (R^2)**: 0.216
   - **Средняя абсолютная ошибка (MAE)**: 0.499
   - **Точность (accuracy)**: 0.54
   - **Отчет по классификации**:
     Модель показала лучшую точность по сравнению с SVC, особенно для классов 5 и 6 (средний диапазон качества). Однако точность для классов с высоким и низким качеством (например, классы 3, 8 и 9) оставалась низкой, что указывает на дисбаланс классов и необходимость доработки модели.

 **Предложения по улучшению**:
   Чтобы повысить точность модели, а также нейросети, можно рассмотреть следующие улучшения:
   - Применение методов борьбы с дисбалансом классов, таких как использование взвешенных классов или генерация синтетических данных (SMOTE).
   - Объединение слабых классов: объединить классы 3, 4 и 5 в один, а классы 6, 7, 8 и 9 — в другой. Это поможет уменьшить влияние редких классов на модель и улучшить её способность классифицировать средние значения качества.
   - Использование более сложных архитектур нейронных сетей .
   - Тонкая настройка гиперпараметров модели для улучшения производительности.

---
